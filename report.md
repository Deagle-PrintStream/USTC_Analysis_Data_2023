# 信息熵在特征选择中的应用

**数据分析及实践 文献调研**

*刘眭怿 PB20061256 2023.5.23*

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [信息熵在特征选择中的应用](#信息熵在特征选择中的应用)
- [前言](#前言)
- [1 相关概念](#1-相关概念)
  - [定义和性质](#定义和性质)
  - [原理和现象](#原理和现象)
  - [基本算法模型](#基本算法模型)
- [2 信息熵在决策树算法中的应用](#2-信息熵在决策树算法中的应用)
  - [决策树ID3算法](#决策树id3算法)
  - [决策树C4.5算法](#决策树c45算法)
- [3 交叉熵在BP神经网络中的应用](#3-交叉熵在bp神经网络中的应用)
- [4 最大熵在马尔科夫模型中的应用](#4-最大熵在马尔科夫模型中的应用)
- [5 特征选择技术概况](#5-特征选择技术概况)
- [6 学习心得](#6-学习心得)
- [参考文献](#参考文献)

<!-- /code_chunk_output -->



**摘要：** 信息熵`(information entropy)`被定义为"接受的每条消息中包含的信息的平均值"，是用于度量数据集中不同字段所含特征的重要参数。特征选择`(Data classification)`主要指从数据的原始特征中选择一个最优特征子集,使得它包含原始特征的全部或大部分分类信息的过程。目前,特征选择是数据挖掘、统计模式识别和机器学习等领域的重要研究课题之一。信息熵在特征选择中有着广泛的应用场景，对信息熵的分析在优化特征选择中有着指导性价值。

**关键词：** 信息熵；特征选择；机器学习；


# 前言

现实中数据集朝着大规模方向发展，样本的维数与日俱增。通常情况下，大规模数据集包含了许多不相关的、冗余或无用的特征。因此，对数据集进行特征筛选有着重要的意义。[^1] 本文聚焦于信息熵，依次介绍了信息熵相关的数学定义、相互联系、基本定理。之后为展示信息熵在特征选择中的应用场景，我们以三种基本的机器学习模型为例，包括决策树、BP神经网络算法、最大熵马尔可夫模型，分析信息熵在模型中的作用范围和作用原理。最后，本文简要介绍介绍特征选择算法的有关研究技术，如特征选择的具体过程、搜索策略、评价标准，进一步展现当今信息熵在对数据处理工作中的重要地位。

# 1 相关概念

## 定义和性质

**自信息(self-information):** 自信息表示某一随机事件发生所带来信息量的多少,因此事件发生的概率大小也决定了自信息的大小。设某随机事件发生的概率为$p$,那么该随机事件的自信息的数学表达式为
$$I(p)=-\log(p)
$$
单位是比特或香农。其函数形式的来源如下：独立事件应具有增量的信息。若$f(x)$是$x$的单调增加函数，且对于任意给定的正整数$m$和$n$，$f(mn)=f(m)+f(n)$成立。我们可以证明，$f(x)$有唯一的函数形式： $f(x)=Klog(x),K\in \mathbb{R}^+$。为简化形式，我们取$K=1$。其中$\log x$代指$\log_2 x$，本文默认$\log$为以$2$为底的对数函数。

**信息熵(information entropy):** 熵最初来源于热力学，指一个系统不受外部干扰时往内部稳定状态发展的特性。在信息论中，熵是接受的每条消息中包含的信息的平均值，被称为信息熵。[^2]其数学表达式为
$$H(A) =-\sum_{i=1}^{n}p(a_i)\log p(a_i)
$$  
$H$的直观解释为：事件结果的稀有程度在样本空间中的加权平均值，代表了随机实验的平均不确定性。用概率论可以解释为：定义自信息函数$\phi(p)=\log \frac{1}{p}$，则$H$为函数$\phi(\cdot)$关于$p$的数学期望。相较于自信息，信息熵表示某一随机分布所带来的信息量的期望，是随机分布中各个自信息的汇总。因此信息熵能够为数据分析带来更大的帮助。

**联合熵(joint entropy):** 将信息熵平行推广至多元变量随机分布的情形就得到了联合熵，以二元情形为例，其数学表达式为
$$H(A,B)=-\sum_{i=1}^{n}\sum_{j=1}^{m}p(a_i,b_j)\log p(a_i,b_j)
$$联合熵的物理意义为：度量了一个联合分布的随机系统的不确定度。

**条件熵(conditional entropy):** 在给定第一个事件$A$的条件下，第二个事件$B$的条件概率分布的熵对第一个事件的期望[^3],数学表达式为：
$$H(B|A)=-\sum_{i=1}^{n}p(a)\sum_{j=1}^{m}p(b|a)\log p(b|a)\\
=-\bigg[\sum_{i=1}^{n}\sum_{j=1}^{m}p(a,b)\log p(a,b)-\sum_{i=1}^{n}p(a)\log p(a)\bigg]
$$条件熵在已知随机变量X的条件下随机变量Y的不确定性。条件熵与联合熵的关系如下，这与概率论中的条件概率分布和联合分布在数学形式上是一致的：
$$
H(A,B)=H(A)+H(B | A)= H(B)+H(A| B)
$$

**相对熵(relevant entropy):** 又称为KL散度，设随机变量X的两个分布为：$p(x),q(x)$，则：
$$
D_{KL}(p||q)=\sum_{x}{\log \frac{p(x)}{q(x)}}=H(p,q)-H(p)
$$相对熵用于衡量两个分布之间的差异，如果两个分布相同，则相对熵为零，否则为正。

**交叉熵(cross entropy):** 设有两个概率分布$p$和概率分布$q$，交叉熵定义为$q$概率分布的自信息对$p$概率分布的期望，数学表达式为：
$$H(p,q) =-\sum_{i=1}^{n}p(a)\log q(a)
$$其中，$p$常取样本的真实概率分布，$q$取预测得到的样本概率分布,此时交叉熵用来衡量在给定的真实分布下，使用非真实分布指定的策略消除系统的不确定性所需要付出努力的大小。[^3]一般的机器学习模型中，直接使用交叉熵作为代价函数

**互信息(interlock-information):** 同样用于表征两个事件单独发生时的信息量重复性，量化了这种重复的信息量的大小。对于两个随机变量$X,Y$，互信息定义为[^4]：
$$
I(x,y)=\sum_{x\in X}\sum_{y\in Y}{p(x,y)\log \frac{p(x,y)}{p(x)*p(y)}}\\
=H(X)+H(Y)-H(X,Y)=H(X,Y)-H(Y|X)-H(X|Y)
$$

**特征熵(term entropy):** 设$D$为样本特征输出的集合，$A$为样本特征，特征熵$H_A(D)$的表达式如下：
$$H_A(D)=−\sum_{i=1}^{n}\frac{|Di|}{|D|}\log\frac{|Di|}{|D|}
$$其中$n$为特征$A$的类别数，$D_i$为特征$A$的第$i$个取值对应的样本个数。$|D|$为样本个数。

## 原理和现象

**最大熵原理(maximum entropy principle):** 最大熵原理指在随机变量分布未知的情况下，选取所有可能分布中具有最大熵的分布作为该随机变量的分布。具体要求是系统中事件发生的概率满足一切已知约束条件，不对任何未知信息做假设，即对于未知的，当作等概率处理。这样可以使信息熵最大，预测风险最小。

**过拟合(over-fitting):** 过拟合指在训练数据不够多的情况下，训练出的模型在训练集上的表现很好，却无法将其应用于测试集。常见的原因是由于干扰性的特征的存在，陷入了局部最优解中。因此常在训练集与测试集外另设一个验证集来避免过拟合。

![over_fitting](./img/over_fitting.png)

常见过拟合的常用方法有：交叉验证，增加噪声，正则化，`Dropout`等。同时，我们可以利用其他的衡量指标来判断模型的性能，例如`F1-score`，作为模型精确率和召回率的一种调和平均，可以消除不同标签的样本量差异过大的问题。

**“峰值”现象(Peaking Phenomena):** 分类器性能与数据维数之间的关系近似满足于一个凹函数：分类器的性能最初随着维数的增加而迅速提高。当维数增加到一定程度时，分类性能达到最高，之后，它随着维数增加而缓慢下降。[^1]
![peak_phenomena](./img/peak_phenomena.png)

一个直观的解释是：训练学习的样本数目有限，但特征数量过大时，模型初始化阶段的超参数无法很好的表现出主要特征，因此训练过程迷失在大量无关特征字段的拟合中。这解释了特征选择的必要性，目的是通过使用统计机器学习方法降低数据的维数，从而加快学习算法效率，降低噪声数据带来的影响，并避免维灾难问题等。

## 基本算法模型

**决策树算法(decision tree algorithm):** 决策树仿照树形结构进行决策，决策树模型常用于分类和回归问题的解决。

常见的决策树算法有`CART`、`ID3`和`C4.5`等，其区别在于选择特征的指标不同。CART方法以基尼系数为指标选择特征，`ID3`和`C4.5`则分别用信息增益、信息增益比来选择特征。我们选择后面二者进行分析。一个决策树模型由三种结点构成，其一为根结点，包含全部样本；其二为叶结点，对应决策结果；其三为内部结点，对应属性测试。

**BP神经网络(BP neural network):** BP神经网络算法模拟了人体神经元的工作过程，是人工神经网络中应用最广泛的神经网络算法之一。[^3]

BP神经网络可以分为三个部分：用于接收数据的输入层、用于处理输入数据及建立相应模型的中间隐藏层和用于输出所建模型结果的输出层。样本数据通过输入层传递给中间的隐藏层，中间隐藏层中包含了各神经元之间连接的权重和传递规则（在机器学习中称之为激活函数），数据在被中间隐藏层处理后到达输出层，输出层通过整理产生了最终结果。在产生结果后，模型对输出的最终结果与数据集的实际结果进行对比，若结果正确则保留原始权重，若结果存在误差且误差超出事先设置的阈值，则回过头对隐含层反馈相应的信息，进而修正权重，直至得到更好的预测结果。

**隐马尔科夫模型(Hidden Markov Model,HMM):** 隐马尔科夫模型是一种概率生成统计模型,它用来描述一个具有隐含未知参数的马尔科夫过程，其核心目标是从可观察的序列中确定隐含层参数，然后利用获得的隐含层参数和观测序列来作进一步的分析。

隐马尔科夫模型常被用于以下三种情境。第一种情境：已知模型的参数和特定观测序列，求在给定模型下该特定观测序列的输出概率。第二种情境：给定某特定的观测序列，求解模型中的参数，使得在求出的模型下，该特定观测序列出现的概率值最大。第三种情境：已知模型的参数，并且给定问题中的观测序列，求解模型中最可能存在的隐藏状态序列。[^4]

# 2 信息熵在决策树算法中的应用

## 决策树ID3算法

`ID3` 使用的分类标准是信息增益，它表示得知特征 $A$ 的信息而使得样本集合不确定性减少的程度。数据集的信息熵定义为：
$$H(D)=-\sum_{k=1}^{K}{\frac{|C_k|}{|D|}\log \frac{|C_k|}{|D|}} $$
其中，$|C_k|,|D|$表示子集和原始数据集的样本数量。针对特征$A$，条件熵为：
$$H(D|A)=\sum_{i=1}^{n}\frac{|D_i|}{|D|}H(D_i)
$$于是我们得到信息增益：
$$Gain(D,A)=H(D)-H(D|A)
$$

`ID3`算法利用信息增益来判断当前节点应当用什么特征来构建决策树，用计算出的信息增益最大的特征来建立决策树的当前节点。具体过程为：
1. 初始化信息增益的阈值。
2. 判断样本是否为同一类输出$D_i$，如果是则返回单节点树$T$。标记类别为$D_i$。
3. 判断特征是否为空，如果是则返回单节点树$T$，标记类别为样本中输出类别$D$实例数最多的类别。
4. 计算$A$中的各个特征（一共$n$个）对输出$D$的信息增益，选择信息增益最大的特征$A_g$。
5. 如果$A_g$的信息增益小于阈值，则返回单节点树$T$，标记类别为样本中输出类别$D$实例数最多的类别。
6. 否则，按特征$A_g$的不同取值$A_{gi}$将对应的样本输出$D$分成不同的类别$D_i$。每个类别产生一个子节点。对应特征值为$A_{gi}$。返回增加了节点的数$T$。
7. 对于所有的子节点，令$D=D_i$,$A=A−${ $A_g$}递归调用2-6步，得到子树$T_i$并返回。

决策树`ID3`算法是建立在奥卡姆剃刀原则的基础上的，其指导理念为：越是小型的决策树越优于大的决策树。它的缺点是没有剪枝操作，且决策步骤较少，容易过拟合。同时它只适用于离散的特征值，对于连续变量，需要进行区间分割处理。

## 决策树C4.5算法

`ID3`算法存在以下问题：一是不能处理连续的特征，二是在相同条件下，取值比较多的特征比取值少的特征信息增益大，用信息增益作为标准容易偏向于取值较多的特征。`C4.5`算法针对`ID3`算法存在的问题进行了相应的改进，引入信息增益率来作为分类标准。

对于连续的特征，`C4.5`算法选择对其进行离散化处理，比如$n$个样本的连续特征$A$，从小到大排列为$a_1,a_2,...,a_n$,`C4.5`取相邻两样本值的平均值，共取得$n-1$个划分点，其中第$i$个划分点$T_i$表示为：$T_i=\frac{a_i+a_{i+1}}{2}$。对于这$n-1$个点，分别计算以该点作为二元分类点时的信息增益。选择信息增益最大的点作为该连续特征的二元离散分类点。

C4.5算法选择使用利用信息增益率来衡量一个特征的划分是否有利：
$$Gain_r(D,A)=\frac {Gain(D,A)}{H(D)}
$$其中$H(D)$即数据集$D$的针对特征$A$的信息熵，称之为特征$A$的固有值。特征数越多，特征对应的特征熵越大。以特征熵作为分母，可以解决信息增益容易偏向于取值较多的特征的问题。

`C4.5`算法决策树的构建过程同上，在此基础上，`C4.5`算法引入了剪枝策略，进一步优化了决策树的结构：以递归的方式从底往上针对每一个非叶子节点，评估用一个最佳叶子节点去代替这棵子树是否有益。如果剪枝后与剪枝前相比其错误率是保持或者下降，则这棵子树就可以被替换。

# 3 交叉熵在BP神经网络中的应用

`BP神经网络`的核心在于将计算输出层输出的结果与实际值进行比较，得到误差后将该误差反向传播到输入层，在反向传播的过程中根据误差修改各种参数的值。模型学习的速度取决于两个值：学习率、偏导值。我们重点关注后者，该值越大，说明模型效果越差，但是该值越大同时也会使得偏导值越大，从而模型学习速度更快。计算预测值与实际值之间误差的方法叫损失函数。传统误差函数的以均方误差最为常见：[^5]
$$
C=\frac{1}{2}\left | a^{(l)}-y\right | ^2_2
$$其中$a^{(l)}$为训练过程中的输出，$y$为真实标签，此时反向传播的更新策略可以表示为：
$$
\hat{q}(c|x)=\arg\min\limits_{q(c|x)}\left\{\sum\limits_{n}\sum\limits_{c}[q(c|x_n)-\delta(c,c_n)]{2}\right\}
$$其中$\delta$为预测结果和真实结果的差值，$q$为指定特征的出现频次。二次代价作为损失函数的方法在实际应用中存在如下问题：更新权重速度过慢，模型学习和收敛速度较慢。这是因为该更新策略中的参数变动相对于步长`epco`是恒定

交叉熵主要是用来判定实际的输出与期望的输出的接近程度。如果我们利用交叉熵作为误差函数：[^6]
$$\hat{q}(c|x)=\arg\min\limits_{q(c|x)}\left\{\sum_{n}c_n\log q(c_n|x_n)\right\}
$$
其中$c_n$为样本的真实值，可以看出，该函数是凸函数，求导时能够得到全局最优值。另一方面，我们可以做到赋予权重的更新速度与差异大小成正比，弥补了二次代价函数的上述缺点。

# 4 最大熵在马尔科夫模型中的应用

最大熵马尔科夫模型是一种集隐马尔科夫模型和最大熵原理的优势于一体的模型。隐马尔可夫模型因为其严格的观测独立性假设，对于具有多个互相作用的观测状态组合以及中长范围的元素依赖的数据环境识别特征的能力有限，而最大熵模型特征选择灵活，且不需要额外的独立性假设或内在约束。

给定数据集$T$、特征函数和约束条件，我们希望找到一个最优的分类器。首先我们采用条件熵
$$H(p(y|x))=-\sum_{x,y}p(x)p(y|x)\log p(y|x)
$$我们的目标是找到：
$$\hat p =\arg \min\limits_{p}\left\{ -H(p(y|x))\right\},\\
s.t. \sum_{x,y}{p(x)p(y|x)f_i(x,y)=\tau_i}\\
\sum_{y}{p(y|x)=1,\forall x}
$$其中$f_i,\tau_i$分布为代价函数和约束的阈值。从数学形式上，最终结果可以表达如下：$$\hat p=\arg\max\limits_{p}\sum_i \tilde{f} (x_i)\log p(x_i),\tilde f\in \mathbb{C(R)},x_i\in\Omega
$$最终结果满足熵的表达形式，可以看到，条件熵是马尔可夫模型的核心判据。

隐马尔可夫是生成模型，学习的是联合概率，必须列举所有观察序列的可能值。而最大熵马尔可夫模型可以在不完整信息下有推导出来未知数据的能力，因为该模型既可以单独决定每个状态，也可以同时考虑其它状态作为特征，进而得到全局优化。

# 5 特征选择技术概况

数据分类是根据事物间的相似性确定样本数据的具体类别的过程，是为了解决大规模数据中出现的计算复杂性问题而衍生出来的研究课题。特征选择的研究起始于上世纪 60 年代，当时主要从统计学的角度出发，所涉及到的特征维数也不高。随着 90 年代新技术的出现和机器学习的兴起，特征选择引起越来越多机器学习领域学者的广泛关注。特征选择算法既可作为分类学习算法的一个预处理步骤，也可成为学习算法的组成部分，学习算法在此简化数据上通常会得到更精确、更容易理解的模型。特征选择的过程可以理解为在两个方向上进行权衡：所选特征子集所含信息量、子集维度大小。

特征选择隶属于降低维数的方法的一种，与之并列的方法还有特征抽取`（Feature extraction）`。后者在处理后依然存在一定的困难：
1. 特征抽取得到的二次特征是原始特征的组合形式，它们一般具有数学意义，但在现实意义上无法解释；
2. 特征抽取并没有减少计算工作量，只是转换数据的表示形式。
3. 特征提取算法的计算复杂度相对而言都比较高

数据挖掘又可细分为以下几种类型：
1. 分类模型，是对事先己知类别的样本数据进行归纳汇总；
2. 回归模型，从历史数据中找出对数值变化规律的准确描述；
3. 聚类模型，根据样本各自不同的特点将一个群体分成多个组或类；
4. 关联模型，利用事物同时出现的规律来发现事物间的关联关系或相关程度；

其中，特征选择在分类模型中的应用最为广泛，特征的数量直接影响了算法的训练时间和预测效果。同时，分类模型是目前研究最广泛、最活跃的课题，并在商业上应用普遍。

在传统选择算法中，特征的信息熵在整个选择过程中是保持不变的，因此近年对动态的互信息的概念研究较为热门。互信息在整个选择过程中是动态估值的，其中那些能被识别的样本在每次选择特征后被剔除，使得它们不再参与互信息或条件互信息的计算过程，同时还能保证每次选择的特征具有最大的信息含量。

# 6 学习心得

在本课程的课堂听讲中：
1. 对数据分析的相关领域有了较为全面的认知；
2. 对数据分析的各个环节有了完整认知，包括数据获取，数据清洗，数据筛查，特征分析等；
3. 对实验报告的撰写格式有了更为清晰的认知，包括摘要，关键词，引言，正文，参考文献等。

在布置的实验完成过程中：
1. 学习编程不是一日之功，每周需要投入时间学习。不可纸上谈兵，需要自己亲自操作，动手印象才会深刻，记得更靠。
2. 掌握了`Python`的基本语法和常见数据结构的使用方法；学会熟练使用`jupyter notebook`进行数据清晰和挖掘工作；
3. 懂得了常见的数据分析方法，包括缺失数值处理，特征提取，数据筛查，关联性分析等。
4. 懂得了常见的预测算法，包括概率回归，贝叶斯模型，卷积神经网络等。

在搜撰写文献调研的报告中：
1. 更清晰的理解了信息熵及其他常用熵的概念，理清了数学表达式的推到过程和适用范围。
2. 深入学习了决策树模型的三个算法：ID3、C4.5、CART、理解了其中的每一个步骤、掌握了建立决策树模型的方法。
3. 初步了解了BP神经网络，理解了它通过反向传播逐步优化所建立模型的原理，体会到了交叉熵作为损失函数带来的优点
4. 掌握了基本的论文撰写格式，提升了自己提炼要点、组织语言的能力。
5. 进一步提升了自己搜索资料的能力，掌握了搜索引擎的常用筛选功能，并提高了对英语网站的阅读和理解能力。
6. 提升了对于编辑语言的熟练度，例如`Markdown`和`Latex`，可以更得心应手地编辑数学公式和应用报告模板，这将在我之后撰写其他课程的报告时起到积极的作用。

# 参考文献

[^1]: 刘华文. 基于信息熵的特征选择算法研究[D].吉林大学,2010.

[^2]: 张璐瑶. 信息熵在机器学习算法中的运用[D].哈尔滨工业大学,2020

[^3]: Kamaledin  G  S.  Competitive  Cross-Entropy  Loss: A  Study  on Training  Single-Layer  Neural  Networks  for  Solving  Nonlinearly  Separable Classification Problems[J]. Neural Processing Letters, 2019, 50(2): 1115-1122.

[^4]: Freitag D, Mc Callum A, Pereira F. Maximum Entropy Markov Models for Information Extraction and Segmentation[C]. Proceedings of The Seventeenth International Conference on Machine Learning, 2000: 591-598.

[^5]: Deng, Jiankang, et al. "Arcface: Additive angular margin loss for deep face recognition." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.

[^6]: Golik P, Doetsch P, Ney H. Cross-Entropy vs. Squared Error Training: A Theoretical and Experimental Comparison[C]. Interspeech, 2013: 1756-1760.
